{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor, FloatTensor\n",
    "\n",
    "import torchvision.models._utils as _utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(inp, oup, stride = 1, leaky = 0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.LeakyReLU(negative_slope=leaky, inplace=True)\n",
    "    )\n",
    "\n",
    "def conv_bn_no_relu(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "    )\n",
    "\n",
    "def conv_bn1X1(inp, oup, stride, leaky=0):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, stride, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.LeakyReLU(negative_slope=leaky, inplace=True)\n",
    "    )\n",
    "\n",
    "def conv_dw(inp, oup, stride, leaky=0.1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "        nn.BatchNorm2d(inp),\n",
    "        nn.LeakyReLU(negative_slope= leaky,inplace=True),\n",
    "\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.LeakyReLU(negative_slope= leaky,inplace=True),\n",
    "    )\n",
    "\n",
    "class SSH(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(SSH, self).__init__()\n",
    "        assert out_channel % 4 == 0\n",
    "        leaky = 0\n",
    "        if (out_channel <= 64):\n",
    "            leaky = 0.1\n",
    "        self.conv3X3 = conv_bn_no_relu(in_channel, out_channel//2, stride=1)\n",
    "\n",
    "        self.conv5X5_1 = conv_bn(in_channel, out_channel//4, stride=1, leaky = leaky)\n",
    "        self.conv5X5_2 = conv_bn_no_relu(out_channel//4, out_channel//4, stride=1)\n",
    "\n",
    "        self.conv7X7_2 = conv_bn(out_channel//4, out_channel//4, stride=1, leaky = leaky)\n",
    "        self.conv7x7_3 = conv_bn_no_relu(out_channel//4, out_channel//4, stride=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        conv3X3 = self.conv3X3(input)\n",
    "\n",
    "        conv5X5_1 = self.conv5X5_1(input)\n",
    "        conv5X5 = self.conv5X5_2(conv5X5_1)\n",
    "\n",
    "        conv7X7_2 = self.conv7X7_2(conv5X5_1)\n",
    "        conv7X7 = self.conv7x7_3(conv7X7_2)\n",
    "\n",
    "        out = torch.cat([conv3X3, conv5X5, conv7X7], dim=1)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self,in_channels_list,out_channels):\n",
    "        super(FPN,self).__init__()\n",
    "        leaky = 0\n",
    "        if (out_channels <= 64):\n",
    "            leaky = 0.1\n",
    "        self.output1 = conv_bn1X1(in_channels_list[0], out_channels, stride = 1, leaky = leaky)\n",
    "        self.output2 = conv_bn1X1(in_channels_list[1], out_channels, stride = 1, leaky = leaky)\n",
    "        self.output3 = conv_bn1X1(in_channels_list[2], out_channels, stride = 1, leaky = leaky)\n",
    "\n",
    "        self.merge1 = conv_bn(out_channels, out_channels, leaky = leaky)\n",
    "        self.merge2 = conv_bn(out_channels, out_channels, leaky = leaky)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # names = list(input.keys())\n",
    "        input = list(input.values())\n",
    "\n",
    "        output1 = self.output1(input[0])\n",
    "        output2 = self.output2(input[1])\n",
    "        output3 = self.output3(input[2])\n",
    "\n",
    "        up3 = F.interpolate(output3, size=[output2.size(2), output2.size(3)], mode=\"nearest\")\n",
    "        output2 = output2 + up3\n",
    "        output2 = self.merge2(output2)\n",
    "\n",
    "        up2 = F.interpolate(output2, size=[output1.size(2), output1.size(3)], mode=\"nearest\")\n",
    "        output1 = output1 + up2\n",
    "        output1 = self.merge1(output1)\n",
    "\n",
    "        out = [output1, output2, output3]\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class MobileNetV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetV1, self).__init__()\n",
    "        self.stage1 = nn.Sequential(\n",
    "            conv_bn(3, 8, 2, leaky = 0.1),    # 3\n",
    "            conv_dw(8, 16, 1),   # 7\n",
    "            conv_dw(16, 32, 2),  # 11\n",
    "            conv_dw(32, 32, 1),  # 19\n",
    "            conv_dw(32, 64, 2),  # 27\n",
    "            conv_dw(64, 64, 1),  # 43\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            conv_dw(64, 128, 2),  # 43 + 16 = 59\n",
    "            conv_dw(128, 128, 1), # 59 + 32 = 91\n",
    "            conv_dw(128, 128, 1), # 91 + 32 = 123\n",
    "            conv_dw(128, 128, 1), # 123 + 32 = 155\n",
    "            conv_dw(128, 128, 1), # 155 + 32 = 187\n",
    "            conv_dw(128, 128, 1), # 187 + 32 = 219\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            conv_dw(128, 256, 2), # 219 +3 2 = 241\n",
    "            conv_dw(256, 256, 1), # 241 + 64 = 301\n",
    "        )\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(256, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.avg(x)\n",
    "        # x = self.model(x)\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class ClassHead(nn.Module):\n",
    "    def __init__(self,inchannels=512,num_anchors=3):\n",
    "        super(ClassHead,self).__init__()\n",
    "        self.num_anchors = num_anchors\n",
    "        self.conv1x1 = nn.Conv2d(inchannels,self.num_anchors*2,kernel_size=(1,1),stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.conv1x1(x)\n",
    "        out = out.permute(0,2,3,1).contiguous()\n",
    "        \n",
    "        return out.view(out.shape[0], -1, 2)\n",
    "\n",
    "class BboxHead(nn.Module):\n",
    "    def __init__(self,inchannels=512,num_anchors=3):\n",
    "        super(BboxHead,self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*4,kernel_size=(1,1),stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.conv1x1(x)\n",
    "        out = out.permute(0,2,3,1).contiguous()\n",
    "\n",
    "        return out.view(out.shape[0], -1, 4)\n",
    "\n",
    "class LandmarkHead(nn.Module):\n",
    "    def __init__(self,inchannels=512,num_anchors=3):\n",
    "        super(LandmarkHead,self).__init__()\n",
    "        self.conv1x1 = nn.Conv2d(inchannels,num_anchors*10,kernel_size=(1,1),stride=1,padding=0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.conv1x1(x)\n",
    "        out = out.permute(0,2,3,1).contiguous()\n",
    "\n",
    "        return out.view(out.shape[0], -1, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original RetinaFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinaFace(nn.Module):\n",
    "    def __init__(self, cfg = None, phase = 'train'):\n",
    "        \"\"\"\n",
    "        :param cfg:  Network related settings.\n",
    "        :param phase: train or test.\n",
    "        \"\"\"\n",
    "        super(RetinaFace,self).__init__()\n",
    "        self.phase = phase\n",
    "        backbone = None\n",
    "        if cfg['name'] == 'mobilenet0.25':\n",
    "            backbone = MobileNetV1()\n",
    "            if cfg['pretrain']:\n",
    "                checkpoint = torch.load(\"./weights/mobilenetV1X0.25_pretrain.tar\", map_location=torch.device('cpu'))\n",
    "                from collections import OrderedDict\n",
    "                new_state_dict = OrderedDict()\n",
    "                for k, v in checkpoint['state_dict'].items():\n",
    "                    name = k[7:]  # remove module.\n",
    "                    new_state_dict[name] = v\n",
    "                # load params\n",
    "                backbone.load_state_dict(new_state_dict)\n",
    "        elif cfg['name'] == 'Resnet50':\n",
    "            import torchvision.models as models\n",
    "            backbone = models.resnet50(pretrained=cfg['pretrain'])\n",
    "\n",
    "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
    "        in_channels_stage2 = cfg['in_channel']\n",
    "        in_channels_list = [\n",
    "            in_channels_stage2 * 2,\n",
    "            in_channels_stage2 * 4,\n",
    "            in_channels_stage2 * 8,\n",
    "        ]\n",
    "        out_channels = cfg['out_channel']\n",
    "        self.fpn = FPN(in_channels_list,out_channels)\n",
    "        self.ssh1 = SSH(out_channels, out_channels)\n",
    "        self.ssh2 = SSH(out_channels, out_channels)\n",
    "        self.ssh3 = SSH(out_channels, out_channels)\n",
    "\n",
    "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
    "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
    "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
    "\n",
    "    def _make_class_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
    "        classhead = nn.ModuleList()\n",
    "        for i in range(fpn_num):\n",
    "            classhead.append(ClassHead(inchannels,anchor_num))\n",
    "        return classhead\n",
    "    \n",
    "    def _make_bbox_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
    "        bboxhead = nn.ModuleList()\n",
    "        for i in range(fpn_num):\n",
    "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
    "        return bboxhead\n",
    "\n",
    "    def _make_landmark_head(self,fpn_num=3,inchannels=64,anchor_num=2):\n",
    "        landmarkhead = nn.ModuleList()\n",
    "        for i in range(fpn_num):\n",
    "            landmarkhead.append(LandmarkHead(inchannels,anchor_num))\n",
    "        return landmarkhead\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        out = self.body(inputs)\n",
    "\n",
    "        # FPN\n",
    "        fpn = self.fpn(out)\n",
    "\n",
    "        # SSH\n",
    "        feature1 = self.ssh1(fpn[0])\n",
    "        feature2 = self.ssh2(fpn[1])\n",
    "        feature3 = self.ssh3(fpn[2])\n",
    "        features = [feature1, feature2, feature3]\n",
    "\n",
    "        bbox_regressions = torch.cat([self.BboxHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
    "        classifications = torch.cat([self.ClassHead[i](feature) for i, feature in enumerate(features)],dim=1)\n",
    "        ldm_regressions = torch.cat([self.LandmarkHead[i](feature) for i, feature in enumerate(features)], dim=1)\n",
    "\n",
    "        if self.phase == 'train':\n",
    "            output = (bbox_regressions, classifications, ldm_regressions)\n",
    "        else:\n",
    "            output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_mnet = {\n",
    "    'name': 'mobilenet0.25',\n",
    "    'min_sizes': [[16, 32], [64, 128], [256, 512]],\n",
    "    'steps': [8, 16, 32],\n",
    "    'variance': [0.1, 0.2],\n",
    "    'clip': False,\n",
    "    'loc_weight': 2.0,\n",
    "    'gpu_train': True,\n",
    "    'batch_size': 32,\n",
    "    'ngpu': 1,\n",
    "    'epoch': 250,\n",
    "    'decay1': 190,\n",
    "    'decay2': 220,\n",
    "    'image_size': 640,\n",
    "    'pretrain': False,\n",
    "    'return_layers': {'stage1': '1', 'stage2': '2', 'stage3': '3'},\n",
    "    'in_channel': 32,\n",
    "    'out_channel': 64\n",
    "}\n",
    "model = RetinaFace(cfg=cfg_mnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN(nn.Module):\n",
    "    def __init__(self,in_channels_list,out_channels):\n",
    "        super(FPN,self).__init__()\n",
    "        leaky = 0\n",
    "        if (out_channels <= 64):\n",
    "            leaky = 0.1\n",
    "        self.output1 = conv_bn1X1(in_channels_list[0], out_channels, stride = 1, leaky = leaky)\n",
    "        self.output2 = conv_bn1X1(in_channels_list[1], out_channels, stride = 1, leaky = leaky)\n",
    "        self.output3 = conv_bn1X1(in_channels_list[2], out_channels, stride = 1, leaky = leaky)\n",
    "\n",
    "        self.merge1 = conv_bn(out_channels, out_channels, leaky = leaky)\n",
    "        self.merge2 = conv_bn(out_channels, out_channels, leaky = leaky)\n",
    "\n",
    "    def forward(self, input: Dict[str, FloatTensor]):\n",
    "        # names = list(input.keys())\n",
    "        input = list(input.values())\n",
    "\n",
    "        output1 = self.output1(input[0])\n",
    "        output2 = self.output2(input[1])\n",
    "        output3 = self.output3(input[2])\n",
    "\n",
    "        up3 = F.interpolate(output3, size=[output2.size(2), output2.size(3)], mode=\"nearest\")\n",
    "        output2 = output2 + up3\n",
    "        output2 = self.merge2(output2)\n",
    "\n",
    "        up2 = F.interpolate(output2, size=[output1.size(2), output1.size(3)], mode=\"nearest\")\n",
    "        output1 = output1 + up2\n",
    "        output1 = self.merge1(output1)\n",
    "\n",
    "        out = [output1, output2, output3]\n",
    "        return out\n",
    "\n",
    "class ScriptRetinaFace(nn.Module):\n",
    "    def __init__(self, cfg=None):\n",
    "        super(ScriptRetinaFace,self).__init__()\n",
    "\n",
    "        backbone = MobileNetV1()\n",
    "        self.body = _utils.IntermediateLayerGetter(backbone, cfg['return_layers'])\n",
    "        in_channels_stage2 = cfg['in_channel']\n",
    "        in_channels_list = [\n",
    "            in_channels_stage2 * 2,\n",
    "            in_channels_stage2 * 4,\n",
    "            in_channels_stage2 * 8,\n",
    "        ]\n",
    "        \n",
    "        out_channels = cfg['out_channel']\n",
    "        self.fpn = FPN(in_channels_list,out_channels)\n",
    "        self.ssh1 = SSH(out_channels, out_channels)\n",
    "        self.ssh2 = SSH(out_channels, out_channels)\n",
    "        self.ssh3 = SSH(out_channels, out_channels)\n",
    "\n",
    "        self.ClassHead = self._make_class_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
    "        self.BboxHead = self._make_bbox_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
    "        self.LandmarkHead = self._make_landmark_head(fpn_num=3, inchannels=cfg['out_channel'])\n",
    "\n",
    "    def _make_class_head(self,fpn_num=3, inchannels=64, anchor_num=2):\n",
    "        classhead = nn.ModuleList()\n",
    "        for i in range(fpn_num):\n",
    "            classhead.append(ClassHead(inchannels, anchor_num))\n",
    "        return classhead\n",
    "    \n",
    "    def _make_bbox_head(self,fpn_num=3, inchannels=64, anchor_num=2):\n",
    "        bboxhead = nn.ModuleList()\n",
    "        for i in range(fpn_num):\n",
    "            bboxhead.append(BboxHead(inchannels,anchor_num))\n",
    "        return bboxhead\n",
    "\n",
    "    def _make_landmark_head(self,fpn_num=3, inchannels=64, anchor_num=2):\n",
    "        landmarkhead = nn.ModuleList()\n",
    "        for i in range(fpn_num):\n",
    "            landmarkhead.append(LandmarkHead(inchannels, anchor_num))\n",
    "        return landmarkhead\n",
    "\n",
    "    def forward(self, inputs: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        out = self.body(inputs)\n",
    "\n",
    "        # FPN\n",
    "        fpn = self.fpn(out)\n",
    "\n",
    "        # SSH\n",
    "        feature1 = self.ssh1(fpn[0])\n",
    "        feature2 = self.ssh2(fpn[1])\n",
    "        feature3 = self.ssh3(fpn[2])\n",
    "        features = [feature1, feature2, feature3]\n",
    "\n",
    "        bbox_regressions = torch.cat([\n",
    "            self.BboxHead[0](features[0]), \n",
    "            self.BboxHead[1](features[1]), \n",
    "            self.BboxHead[2](features[2]), \n",
    "        ], dim=1)\n",
    "        classifications = torch.cat([\n",
    "            self.ClassHead[0](features[0]),\n",
    "            self.ClassHead[1](features[1]),\n",
    "            self.ClassHead[2](features[2]),\n",
    "        ], dim=1)\n",
    "        ldm_regressions = torch.cat([\n",
    "            self.LandmarkHead[0](features[0]),\n",
    "            self.LandmarkHead[1](features[1]),\n",
    "            self.LandmarkHead[2](features[2])\n",
    "        ], dim=1)\n",
    "\n",
    "        output = (bbox_regressions, F.softmax(classifications, dim=-1), ldm_regressions)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScriptRetinaFace(cfg=cfg_mnet)\n",
    "model.eval()\n",
    "model.to(\"cuda\")\n",
    "scripted_model = torch.jit.script(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_inp = torch.rand(16, 3, 1024, 1024, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.all(scripted_model(rand_inp)[0] == scripted_model(rand_inp)[0]))\n",
    "print(torch.all(scripted_model(rand_inp)[1] == scripted_model(rand_inp)[1]))\n",
    "print(torch.all(scripted_model(rand_inp)[2] == scripted_model(rand_inp)[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit model(rand_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit scripted_model(rand_inp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_surveillance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa4b068902e3001b4bd121ae49c0267b271c2e36d042e15dbcdc0e7db02f0a21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
