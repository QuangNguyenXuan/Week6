{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjOS26g20Kmi"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE21CH-B0Kmm"
      },
      "source": [
        "### Scripting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3Pv2krX0Kmn"
      },
      "outputs": [],
      "source": [
        "def my_function(x):\n",
        "    if x.mean() > 1.0:\n",
        "        r = torch.tensor(1.0)\n",
        "    else:\n",
        "        r = torch.tensor(2.0)\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuCU0ZHW0Kmo",
        "outputId": "e09f1655-0d72-4cac-e59a-9c8009e7106d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "graph(%x.1 : Tensor):\n",
              "  %10 : bool = prim::Constant[value=0]()\n",
              "  %2 : NoneType = prim::Constant()\n",
              "  %4 : float = prim::Constant[value=1.]() # <ipython-input-3-e20642937d0c>:2:18\n",
              "  %12 : float = prim::Constant[value=2.]() # <ipython-input-3-e20642937d0c>:5:25\n",
              "  %3 : Tensor = aten::mean(%x.1, %2) # <ipython-input-3-e20642937d0c>:2:7\n",
              "  %5 : Tensor = aten::gt(%3, %4) # <ipython-input-3-e20642937d0c>:2:7\n",
              "  %7 : bool = aten::Bool(%5) # <ipython-input-3-e20642937d0c>:2:7\n",
              "  %r : Tensor = prim::If(%7) # <ipython-input-3-e20642937d0c>:2:4\n",
              "    block0():\n",
              "      %r.1 : Tensor = aten::tensor(%4, %2, %2, %10) # <ipython-input-3-e20642937d0c>:3:12\n",
              "      -> (%r.1)\n",
              "    block1():\n",
              "      %r.3 : Tensor = aten::tensor(%12, %2, %2, %10) # <ipython-input-3-e20642937d0c>:5:12\n",
              "      -> (%r.3)\n",
              "  return (%r)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "fscript = torch.jit.script(my_function)\n",
        "fscript.graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyfEfNfC0Kmo",
        "outputId": "79e3e5f3-b2ba-45fc-84fb-c4db6696701f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "fscript(torch.ones(2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18Q8tQG70Kmp"
      },
      "source": [
        "### Tracing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0efi6Hlo0Kmp"
      },
      "outputs": [],
      "source": [
        "def my_function(x):\n",
        "    if x.mean() > 1.0:\n",
        "        r = torch.tensor(1.0)\n",
        "    else:\n",
        "        r = torch.tensor(2.0)\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuNx3V1I0Kmp",
        "outputId": "8b500c51-0754-495f-acb1-c30398660ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e20642937d0c>:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if x.mean() > 1.0:\n",
            "<ipython-input-6-e20642937d0c>:5: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  r = torch.tensor(2.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "graph(%x : Float(2, 2, strides=[2, 1], requires_grad=0, device=cpu)):\n",
              "  %5 : Float(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # <ipython-input-6-e20642937d0c>:5:0\n",
              "  %6 : Device = prim::Constant[value=\"cpu\"]() # <ipython-input-6-e20642937d0c>:5:0\n",
              "  %7 : int = prim::Constant[value=6]() # <ipython-input-6-e20642937d0c>:5:0\n",
              "  %8 : bool = prim::Constant[value=0]() # <ipython-input-6-e20642937d0c>:5:0\n",
              "  %9 : bool = prim::Constant[value=0]() # <ipython-input-6-e20642937d0c>:5:0\n",
              "  %10 : NoneType = prim::Constant()\n",
              "  %11 : Float(requires_grad=0, device=cpu) = aten::to(%5, %6, %7, %8, %9, %10) # <ipython-input-6-e20642937d0c>:5:0\n",
              "  %12 : Float(requires_grad=0, device=cpu) = aten::detach(%11) # <ipython-input-6-e20642937d0c>:5:0\n",
              "  return (%12)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ftrace = torch.jit.trace(my_function, torch.ones(2, 2))\n",
        "ftrace.graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1KLqTIe0Kmq",
        "outputId": "86525248-ce5c-4d6e-cdf6-9cf4e570739e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ftrace(torch.ones(2, 2).add_(1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl2k_Ijr0Kmq",
        "outputId": "6df8c534-1b5e-4f35-ef6b-af6e455a2587"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "fscript(torch.ones(2, 2).add_(1.0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fscript.code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "rl--z31t1DMS",
        "outputId": "a354f6ea-8f8e-44d5-99ea-f3f27c53dab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def my_function(x: Tensor) -> Tensor:\\n  if bool(torch.gt(torch.mean(x), 1.)):\\n    r = torch.tensor(1.)\\n  else:\\n    r = torch.tensor(2.)\\n  return r\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ftrace.code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "NGILVQHI1OCI",
        "outputId": "9d55db68-d474-48cd-a83c-063fc01ea5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def my_function(x: Tensor) -> Tensor:\\n  _0 = torch.to(CONSTANTS.c0, torch.device(\"cpu\"), 6)\\n  return torch.detach(_0)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fscript.save(\"my_func.pt\")"
      ],
      "metadata": {
        "id": "NUxJBIfw1VPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip my_func.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bapgb_9d1heZ",
        "outputId": "419dbfa2-084e-41c6-8357-d8535e519d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  my_func.pt\n",
            " extracting: my_func/data.pkl        \n",
            "  inflating: my_func/code/__torch__.py  \n",
            "  inflating: my_func/code/__torch__.py.debug_pkl  \n",
            " extracting: my_func/constants.pkl   \n",
            " extracting: my_func/version         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ftrace.save(\"traced_my_func.pt\")"
      ],
      "metadata": {
        "id": "S_dM9teY1z8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip traced_my_func.pt"
      ],
      "metadata": {
        "id": "x5MiNEYx15OS",
        "outputId": "d626d995-3b9f-4d0d-f1d6-40dd4b9397f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  traced_my_func.pt\n",
            " extracting: traced_my_func/data.pkl  \n",
            "  inflating: traced_my_func/code/__torch__.py  \n",
            "  inflating: traced_my_func/code/__torch__.py.debug_pkl  \n",
            " extracting: traced_my_func/constants/0  \n",
            " extracting: traced_my_func/constants.pkl  \n",
            " extracting: traced_my_func/version  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "corrosion_detector",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3dc88fab23fa01d025ff7625057278ed34559c7e21280c6ea1d0c4a6a61d2522"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}