{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2af72e65-1350-4dd8-adc8-7e761994d4b7",
      "metadata": {
        "id": "2af72e65-1350-4dd8-adc8-7e761994d4b7"
      },
      "source": [
        "\n",
        "## Initially we have this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "942628d6-fe13-48df-8b2c-6c02a5a29ff5",
      "metadata": {
        "id": "942628d6-fe13-48df-8b2c-6c02a5a29ff5"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "from itertools import product\n",
        "from typing import Tuple\n",
        "\n",
        "STEPS = [8, 16, 32]\n",
        "MIN_SIZES = [[16, 32], [64, 128], [256, 512]]\n",
        "\n",
        "def calculate_anchors(image_size: Tuple[int, int]):\n",
        "    feature_maps = [[ceil(image_size[0]/step), ceil(image_size[1]/step)] for step in STEPS]\n",
        "    anchors = []\n",
        "    for k, f in enumerate(feature_maps):\n",
        "        min_sizes = MIN_SIZES[k]\n",
        "        for i, j in product(range(f[0]), range(f[1])):\n",
        "            for min_size in min_sizes:\n",
        "                s_kx = min_size / image_size[1]\n",
        "                s_ky = min_size / image_size[0]\n",
        "                dense_cx = [x * STEPS[k] / image_size[1] for x in [j + 0.5]]\n",
        "                dense_cy = [y * STEPS[k] / image_size[0] for y in [i + 0.5]]\n",
        "                for cy, cx in product(dense_cy, dense_cx):\n",
        "                    anchors += [cx, cy, s_kx, s_ky]\n",
        "    return anchors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b98bfa-01a1-4c8d-9fd2-6da24eaa0a18",
      "metadata": {
        "id": "67b98bfa-01a1-4c8d-9fd2-6da24eaa0a18"
      },
      "outputs": [],
      "source": [
        "%timeit calculate_anchors((640, 480))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9957271-b57b-4b3d-bbb1-356d97ae0eac",
      "metadata": {
        "id": "c9957271-b57b-4b3d-bbb1-356d97ae0eac"
      },
      "source": [
        "## Let's add some caching with a hash table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fa7f07c-d1e1-46a8-b12e-0576d4634410",
      "metadata": {
        "id": "7fa7f07c-d1e1-46a8-b12e-0576d4634410"
      },
      "outputs": [],
      "source": [
        "caches = {}\n",
        "\n",
        "def calculate_anchors_with_caching(image_size: Tuple[int, int]):\n",
        "    if image_size in caches:\n",
        "        return caches[image_size]\n",
        "    \n",
        "    feature_maps = [[ceil(image_size[0]/step), ceil(image_size[1]/step)] for step in STEPS]\n",
        "    anchors = []\n",
        "    for k, f in enumerate(feature_maps):\n",
        "        min_sizes = MIN_SIZES[k]\n",
        "        for i, j in product(range(f[0]), range(f[1])):\n",
        "            for min_size in min_sizes:\n",
        "                s_kx = min_size / image_size[1]\n",
        "                s_ky = min_size / image_size[0]\n",
        "                dense_cx = [x * STEPS[k] / image_size[1] for x in [j + 0.5]]\n",
        "                dense_cy = [y * STEPS[k] / image_size[0] for y in [i + 0.5]]\n",
        "                for cy, cx in product(dense_cy, dense_cx):\n",
        "                    anchors += [cx, cy, s_kx, s_ky]\n",
        "\n",
        "    caches[image_size] = image_size\n",
        "    return anchors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554eea02-ada0-41d0-a586-892b6131eff2",
      "metadata": {
        "id": "554eea02-ada0-41d0-a586-892b6131eff2"
      },
      "outputs": [],
      "source": [
        "%timeit calculate_anchors_with_caching((640, 480))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34b4fc8-e98f-49c2-bca6-5acecb38e17a",
      "metadata": {
        "id": "c34b4fc8-e98f-49c2-bca6-5acecb38e17a"
      },
      "source": [
        "## So let's say the input size changes a lot, that's cheating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb961f49-9ec1-4f52-ac2f-57a6e9a44458",
      "metadata": {
        "id": "cb961f49-9ec1-4f52-ac2f-57a6e9a44458"
      },
      "outputs": [],
      "source": [
        "input_sizes = [(640+i, 480+i) for i in range(1000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b97ef9-9da7-4e16-a662-c060b1a2cbaf",
      "metadata": {
        "id": "10b97ef9-9da7-4e16-a662-c060b1a2cbaf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "%timeit calculate_anchors_with_caching(random.choice(input_sizes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c2bc61-c4d1-4cc1-9948-bfa535d9a33d",
      "metadata": {
        "id": "f0c2bc61-c4d1-4cc1-9948-bfa535d9a33d"
      },
      "outputs": [],
      "source": [
        "%timeit calculate_anchors(random.choice(input_sizes))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8a21aa7-5e20-4cdf-9932-781eba704ab0",
      "metadata": {
        "id": "d8a21aa7-5e20-4cdf-9932-781eba704ab0"
      },
      "source": [
        "## Numba does not support Global, so let's just move them to the local scope for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0dbdbe6-3ac0-472c-8797-62f3e1d5b1f7",
      "metadata": {
        "id": "e0dbdbe6-3ac0-472c-8797-62f3e1d5b1f7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "from numba import njit, prange\n",
        "import numpy as np\n",
        "\n",
        "@njit()\n",
        "def calculate_anchors_numba(image_size: Tuple[int, int]) -> List[List[int]]:\n",
        "    steps = [8, 16, 32]\n",
        "    min_sizes_cfg = [[16, 32], [64, 128], [256, 512]]\n",
        "    feature_maps = [[ceil(image_size[0]/step), ceil(image_size[1]/step)] for step in steps]\n",
        "    anchors: List[List[int]] = []\n",
        "    for k in range(len(feature_maps)):\n",
        "        for i in range(feature_maps[k][0]):\n",
        "            for j in range(feature_maps[k][1]):\n",
        "                for min_size in min_sizes_cfg[k]:\n",
        "                    s_kx = min_size / image_size[1]\n",
        "                    s_ky = min_size / image_size[0]\n",
        "                    cx = (j + 0.5) * steps[k] / image_size[1]\n",
        "                    cy = (i + 0.5) * steps[k] / image_size[0]\n",
        "                    anchors.append([cx, cy, s_kx, s_ky])\n",
        "    return anchors\n",
        "\n",
        "# Warm up\n",
        "for _ in range(10):\n",
        "    calculate_anchors_numba(random.choice(input_sizes))\n",
        "\n",
        "%timeit calculate_anchors_numba(random.choice(input_sizes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e4bcdf-49d6-4f9d-bbff-58f99d9ea111",
      "metadata": {
        "id": "f7e4bcdf-49d6-4f9d-bbff-58f99d9ea111"
      },
      "outputs": [],
      "source": [
        "res = calculate_anchors_numba((640, 480))\n",
        "print(len(res))\n",
        "res2 = calculate_anchors((640, 480))\n",
        "res2 = np.array(res2)\n",
        "print(res2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd31e90c-25f6-4e85-b662-b5b2c488250f",
      "metadata": {
        "id": "fd31e90c-25f6-4e85-b662-b5b2c488250f"
      },
      "outputs": [],
      "source": [
        "list(product([1,2,3], [4,5,6]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fdf9a2c-5870-46ea-a538-d4c29f94fd0d",
      "metadata": {
        "id": "0fdf9a2c-5870-46ea-a538-d4c29f94fd0d"
      },
      "source": [
        "# 3x faster already, can we do more ? time for vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a63b775-2805-4b32-a988-fc24f7047be6",
      "metadata": {
        "id": "1a63b775-2805-4b32-a988-fc24f7047be6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "import numpy as np\n",
        "\n",
        "# @njit()\n",
        "def calculate_anchors_numba_more(image_size: Tuple[int, int]) -> np.ndarray:\n",
        "    steps = np.array([8, 16, 32])\n",
        "    min_sizes_cfg = [[16, 32], [64, 128], [256, 512]]\n",
        "    feature_maps = np.array([[ceil(image_size[0]/step), ceil(image_size[1]/step)] for step in steps])\n",
        "    \n",
        "    num_anchors = 0\n",
        "    num_anchors_per_fm: List[int] = []\n",
        "    for k in range(len(feature_maps)):\n",
        "        curr = feature_maps[k][0] * feature_maps[k][1] * len(min_sizes_cfg[k])\n",
        "        num_anchors_per_fm.append(curr)\n",
        "        num_anchors += curr\n",
        "            \n",
        "    # For k\n",
        "    temp_np = np.zeros((num_anchors, 4), dtype=np.float64)\n",
        "    start = 0\n",
        "    for i, e in enumerate(num_anchors_per_fm):\n",
        "        temp_np_sub_i = temp_np[start:start+e,:]\n",
        "        temp_np_sub_i[:, 3] = i\n",
        "        \n",
        "        # i will then be in range of (0, feature_maps[k][0]), each i be duplicated feature_maps[k][1] * len(min_sizes_cfg[k]) times\n",
        "        nums_repeat_i = feature_maps[i][1] * len(min_sizes_cfg[i])\n",
        "        arrange = np.arange(0, feature_maps[i][0], 1)\n",
        "        repeated = np.repeat(arrange, nums_repeat_i)\n",
        "        temp_np_sub_i[:, 0] = repeated\n",
        "        start += e\n",
        "\n",
        "        # j will then be in range of (0, feature_maps[k][1]), each j be duplicated len(min_sizes_cfg[k]) times. Then duplicate this whole j array for each i for feature_maps[k][0] times \n",
        "        nums_repeat_j = len(min_sizes_cfg[i])\n",
        "        arrange = np.arange(0, feature_maps[i][1], 1)\n",
        "        repeated = np.tile(np.repeat(arrange, nums_repeat_j), feature_maps[i][0])\n",
        "        temp_np_sub_i[:, 1] = repeated\n",
        "        \n",
        "        # Now min_sizes_cfg[i] will be duplicated feature_maps[k][0] * feature_maps[k][1] time\n",
        "        nums_repeat_min_size = feature_maps[i][0] * feature_maps[i][1]\n",
        "        repeated = np.tile(min_sizes_cfg[i], nums_repeat_min_size)\n",
        "        temp_np_sub_i[:, 2] = repeated\n",
        "            \n",
        "\n",
        "    res = np.zeros((num_anchors, 4), dtype=np.float64)\n",
        "    res[:, 2] = temp_np[:, 2] / image_size[1]\n",
        "    res[:, 3] = temp_np[:, 2] / image_size[0]\n",
        "    res[:, 0] = (temp_np[:, 1] + 0.5) * steps[temp_np[:, 3].astype(np.int32)] / image_size[1]\n",
        "    res[:, 1] = (temp_np[:, 0] + 0.5) * steps[temp_np[:, 3].astype(np.int32)] / image_size[0]\n",
        "\n",
        "    return res.flatten()\n",
        "\n",
        "# Warm up\n",
        "for _ in range(2):\n",
        "    calculate_anchors_numba_more(random.choice(input_sizes))\n",
        "\n",
        "%timeit calculate_anchors_numba_more(random.choice(input_sizes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddc4fb9-dc94-4faf-9dae-3cdc007742cf",
      "metadata": {
        "id": "3ddc4fb9-dc94-4faf-9dae-3cdc007742cf"
      },
      "outputs": [],
      "source": [
        "res_1 = calculate_anchors((640, 480))\n",
        "res_2 = calculate_anchors_numba_more((640, 480))\n",
        "res_1 = np.array(res_1)\n",
        "print(res_1.shape, res_2.shape)\n",
        "res_1[0], res_2[0]\n",
        "np.all(res_1 == res_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f88bad6-aa99-4e5b-8573-11ea4f2b65ec",
      "metadata": {
        "id": "8f88bad6-aa99-4e5b-8573-11ea4f2b65ec"
      },
      "source": [
        "## Nows that 35 times faster\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def std(xs):\n",
        "    mean = 0\n",
        "    for x in xs:\n",
        "        mean += x\n",
        "    mean = mean/len(xs)\n",
        "\n",
        "    mean_squared = 0\n",
        "    for x in xs:\n",
        "        mean_squared = (mean - x)**2\n",
        "    variance = mean_squared / len(xs)\n",
        "\n",
        "    return math.sqrt(variance)\n"
      ],
      "metadata": {
        "id": "1OJ3IT-8Bn-U"
      },
      "id": "1OJ3IT-8Bn-U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppBEGfvdCbBx"
      },
      "id": "ppBEGfvdCbBx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "%timeit std(np.random.normal(0, 1, 10000000))"
      ],
      "metadata": {
        "id": "WhHQC1LsCJEZ"
      },
      "id": "WhHQC1LsCJEZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import njit\n",
        "\n",
        "numba_std = njit(std)\n",
        "%timeit numba_std(np.random.normal(0, 1, 10000000))"
      ],
      "metadata": {
        "id": "IG1sHN8cC9ZW"
      },
      "id": "IG1sHN8cC9ZW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit std(np.random.normal(0, 1, 10))"
      ],
      "metadata": {
        "id": "d30kZgm7DRUH"
      },
      "id": "d30kZgm7DRUH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit numba_std(np.random.normal(0, 1, 10))"
      ],
      "metadata": {
        "id": "ucExLxbUDVeQ"
      },
      "id": "ucExLxbUDVeQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_sqrt(x):\n",
        "    return math.sqrt(x)"
      ],
      "metadata": {
        "id": "tjFEQkCbDa9J"
      },
      "id": "tjFEQkCbDa9J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit simple_sqrt(3)"
      ],
      "metadata": {
        "id": "NUT-2FxdDe_e"
      },
      "id": "NUT-2FxdDe_e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numba_simple_sqrt = njit(simple_sqrt)\n",
        "\n",
        "%timeit numba_simple_sqrt(3)"
      ],
      "metadata": {
        "id": "jELeBl1ODkGT"
      },
      "id": "jELeBl1ODkGT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}