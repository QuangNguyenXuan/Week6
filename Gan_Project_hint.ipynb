{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Modules"
      ],
      "metadata": {
        "id": "5soQrbQYRlG9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfIk2es3hJEd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "#import tensorflow_probability as tfp\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs"
      ],
      "metadata": {
        "id": "bZhhLBN5Rp4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########### YOUR CODE HERE ################\n",
        "\"\"\"Tùy thuộc vào cách load data để cần 1 hay\n",
        "nhiều path tới data ở đây mình dùng 2 nếu các \n",
        "bạn dùng ít hoặc nhiệu hơn thì có thể xóa hoặc \n",
        "khai báo thêm\"\"\"\n",
        "\n",
        "# Path tới data folder \n",
        "PATH = \n",
        "###########################################\n",
        "\n",
        "BUFFER_SIZE = 20\n",
        "BATCH_SIZE  = 1\n",
        "IMG_WIDTH   = 1024\n",
        "IMG_HEIGHT  = 256\n",
        "\n",
        "LOW_WIDTH   = 256\n",
        "LOW_HEIGHT  = 64"
      ],
      "metadata": {
        "id": "eG5eAXKERswz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data"
      ],
      "metadata": {
        "id": "xXPXkF6BRvEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load(image_path):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    Thực hiện các bước load ảnh và xử lý ảnh cơ bản\n",
        "    Parameters\n",
        "    ----------\n",
        "    image_path : string \n",
        "        Path dẫn đến file ảnh.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    image_lr: tf.Tensor (tf.float32)\n",
        "        ảnh input low resolution và nhiễu \n",
        "    target_lr: tf.Tensor (tf.float32)\n",
        "        ảnh target low resolution không bị nhiễu \n",
        "    target_hr: tf.Tensor (tf.float32)\n",
        "        ảnh target high resolution \n",
        "    \"\"\"\n",
        "    \n",
        "    # read file và decode ảnh\n",
        "     \n",
        "    # resize image_lr, target_lr theo LOW_WIDTH và LOW_HEIGHT\n",
        "    \n",
        "    # resize target_hr  IMG_WIDTH và IMG_HEIGHT\n",
        "    \n",
        "    # Convert cả ảnh thành float32 tensors\n",
        "    \n",
        "    # tạo ma trận noise có size theo LOW_WIDTH và LOW_HEIGHT\n",
        "\n",
        "    # image_lr nhân với ma trận noise để tạo ảnh nhiễu\n",
        "    \n",
        "    \n",
        "    \n",
        "    return image_lr, target_lr, target_hr\n",
        "    ###########################################"
      ],
      "metadata": {
        "id": "c0rGt-ZHZQW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwwYQpu9FzDu"
      },
      "outputs": [],
      "source": [
        "def normalize(image_lr, target_lr, target_hr):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    normalizing the images to [-1, 1]    \n",
        "    Parameters\n",
        "    ----------\n",
        "    image_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh input low resolution và nhiễu\n",
        "    target_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh target low resolution  \n",
        "    target_hr    : tf.Tensor (tf.float32) \n",
        "        ảnh target high resolution \n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    image_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh input low resolution và nhiễu\n",
        "    target_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh target low resolution  \n",
        "    target_hr    : tf.Tensor (tf.float32) \n",
        "        ảnh target high resolution \n",
        "    \"\"\"\n",
        "\n",
        "    return image_lr, target_lr, target_hr\n",
        "    ###########################################\n",
        "\n",
        "#@tf.function()\n",
        "def random_jitter(image_lr, target_lr, target_hr):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    Có 50% cơ hội thực hiện flip ảnh từ trái sang phải \n",
        "    Parameters\n",
        "    ----------\n",
        "    image_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh input low resolution và nhiễu\n",
        "    target_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh target low resolution  \n",
        "    target_hr    : tf.Tensor (tf.float32) \n",
        "        ảnh target high resolution\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    image_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh input low resolution và nhiễu\n",
        "    target_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh target low resolution  \n",
        "    target_hr    : tf.Tensor (tf.float32) \n",
        "        ảnh target high resolution\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    return image_lr, target_lr, target_hr\n",
        "    ###########################################\n",
        "    \n",
        "\n",
        "def load_image_train(image_path):\n",
        "    ########### YOUR CODE HERE ################\n",
        "    \"\"\" Thực hiện load image, random_jitter, và normalize ảnh \n",
        "    Parameters\n",
        "    ----------\n",
        "    image_path    : string\n",
        "        path nơi chứa ảnh data\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    image_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh input low resolution và nhiễu\n",
        "    target_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh target low resolution  \n",
        "    target_hr    : tf.Tensor (tf.float32) \n",
        "        ảnh target high resolution\n",
        "    \"\"\"\n",
        "    # load ảnh \n",
        "\n",
        "    # random jiter \n",
        "\n",
        "    # normalize ảnh\n",
        "\n",
        "\n",
        "    return image_lr, target_lr, target_hr\n",
        "    ###########################################\n",
        "\n",
        "\n",
        "\n",
        "def load_image_test(image_path):\n",
        "    ########### YOUR CODE HERE ################\n",
        "    \"\"\" Thực hiện load image, và normalize ảnh \n",
        "    Parameters\n",
        "    ----------\n",
        "    image_path    : string\n",
        "        path nơi chứa ảnh data\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    image_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh input low resolution và nhiễu\n",
        "    target_lr     : tf.Tensor (tf.float32) \n",
        "        ảnh target low resolution  \n",
        "    target_hr    : tf.Tensor (tf.float32) \n",
        "        ảnh target high resolution\n",
        "    \"\"\"\n",
        "    # load ảnh \n",
        "\n",
        "    # normalize ảnh\n",
        "\n",
        "\n",
        "    return image_lr, target_lr, target_hr\n",
        "    ###########################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQHmYSmk8b4b"
      },
      "outputs": [],
      "source": [
        "# train_dataset\n",
        "########### YOUR CODE HERE ################\n",
        "#thay đổi đường dẫn phù hợp\n",
        "train_dataset = tf.data.Dataset.list_files(PATH+'/train/*.png')\n",
        "###########################################\n",
        "train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(1)\n",
        "\n",
        "# test_dataset\n",
        "########### YOUR CODE HERE ################\n",
        "#thay đổi đường dẫn phù hợp\n",
        "test_dataset = tf.data.Dataset.list_files(PATH+'/val/*.png')\n",
        "###########################################\n",
        "test_dataset = test_dataset.map(load_image_test)\n",
        "test_dataset = test_dataset.batch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ],
      "metadata": {
        "id": "XJyFQWJDSXPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blocks"
      ],
      "metadata": {
        "id": "uCnnsE4tSdEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r1PyIqNN5DE"
      },
      "outputs": [],
      "source": [
        "def extract_first_features(filters, size, apply_batchnorm=True):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    Extract feature của input images CONV2D -> BN(bool) -> LeakyRelu\n",
        "    padding = same, stride = 1\n",
        "    Parameters\n",
        "    ----------\n",
        "    filters         : int\n",
        "        số lượng filters\n",
        "    size            : int\n",
        "        size của filter\n",
        "    apply_batchnorm : bool\n",
        "        có sử dụng batchnorm hay không \n",
        "    Returns\n",
        "    -------\n",
        "    result: (tùy thuộc vd Sequential)\n",
        "        block CONV2D -> BN(bool) -> LeakyRelu\n",
        "    \"\"\"\n",
        "    # Conv2D stride=1\n",
        "    # check apply_batchnorm nếu True thì dùng \n",
        "    # leakyRelu \n",
        "    \n",
        "    return result\n",
        "    ###########################################\n",
        "    \n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    downsample trong Unet CONV2D -> BN(bool) -> LeakyRelu\n",
        "    Parameters\n",
        "    ----------\n",
        "    filters         : int\n",
        "        số lượng filters\n",
        "    size            : int\n",
        "        size của filter\n",
        "    apply_batchnorm : bool\n",
        "        có sử dụng batchnorm hay không \n",
        "    Returns\n",
        "    -------\n",
        "    result: (tùy thuộc vd Sequential)\n",
        "        block CONV2D -> BN(bool) -> LeakyRelu\n",
        "    \"\"\"\n",
        "    # Conv2D stride=2\n",
        "    # check apply_batchnorm nếu True thì dùng \n",
        "    # leakyRelu \n",
        "    \n",
        "    return result\n",
        "    ###########################################\n",
        "    \n",
        "\n",
        "\n",
        "def downsample_dis(filters, size_12, size_3, apply_batchnorm=True):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    downsample dành cho discriminator trong Unet CONV2D -> CONV2D -> CONV2D -> BN(bool) -> LeakyRelu\n",
        "    Parameters\n",
        "    ----------\n",
        "    filters         : int\n",
        "        số lượng filters\n",
        "    size_12         : int\n",
        "        kernel size cho CONV2D 1 và 2\n",
        "    size_3          : int\n",
        "        kernel size cho CONV2D 3\n",
        "    apply_batchnorm : bool\n",
        "        có sử dụng batchnorm hay không \n",
        "    Returns\n",
        "    -------\n",
        "    result: (tùy thuộc vd Sequential)\n",
        "        CONV2D -> CONV2D -> CONV2D -> BN(bool) -> LeakyRelu\n",
        "    \"\"\"\n",
        "    # Conv2D stride=1 kernel_size=size_12\n",
        "    # Conv2D stride=1 kernel_size=size_12\n",
        "    # Conv2D stride=2 kernel_size=size_3\n",
        "    # check apply_batchnorm nếu True thì dùng \n",
        "    # leakyRelu \n",
        "    \n",
        "    return result\n",
        "    ###########################################\n",
        "    \n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    upsample trong Unet Conv2DTranspose -> BN -> Dropout(bool) -> Relu\n",
        "    Parameters\n",
        "    ----------\n",
        "    filters         : int\n",
        "        path nơi chứa ảnh data (4 ảnh nhỏ để split)\n",
        "    size            : int\n",
        "        kernel size\n",
        "    apply_dropout : bool\n",
        "        có sử dụng Dropout hay không \n",
        "    Returns\n",
        "    -------\n",
        "    result: (tùy thuộc vd Sequential)\n",
        "        Conv2DTranspose -> BN -> Dropout(bool) -> LeakyRelu\n",
        "    \"\"\"\n",
        "    # Conv2DTranspose stride=2\n",
        "    # BatchNorm\n",
        "    # check apply_dropout nếu True thì dùng \n",
        "    # Relu \n",
        "    \n",
        "    return result\n",
        "    ###########################################\n",
        "\n",
        "def downsample_sr(filters, size, apply_batchnorm=True):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    downsample cho super resolution Conv2D -> BN(bool) -> LeakyRelu \n",
        "    padding = same, stride = 1\n",
        "    Parameters\n",
        "    ----------\n",
        "    filters         : int\n",
        "        path nơi chứa ảnh data (4 ảnh nhỏ để split)\n",
        "    size            : int\n",
        "        kernel size\n",
        "    apply_batchnorm : bool\n",
        "        có sử dụng Dropout hay không \n",
        "    Returns\n",
        "    -------\n",
        "    result: (tùy thuộc vd Sequential)\n",
        "        Conv2D -> BN -> LeakyRelu\n",
        "    \"\"\"\n",
        "    # Conv2D stride=1\n",
        "    # check apply_batchnorm nếu True thì dùng \n",
        "    # leakyRelu \n",
        "    \n",
        "    return result\n",
        "    ###########################################\n",
        "\n",
        "def upsample_sr(filters, size, apply_dropout=False):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    upsample trong super resolution Conv2DTranspose -> BN -> Dropout(bool) -> LeakyRelu\n",
        "    Parameters\n",
        "    ----------\n",
        "    filters         : int\n",
        "        path nơi chứa ảnh data (4 ảnh nhỏ để split)\n",
        "    size            : int\n",
        "        kernel size\n",
        "    apply_dropout : bool\n",
        "        có sử dụng Dropout hay không \n",
        "    Returns\n",
        "    -------\n",
        "    result: (tùy thuộc vd Sequential)\n",
        "        Conv2DTranspose -> BN -> Dropout(bool) -> LeakyRelu\n",
        "    \"\"\"\n",
        "    # Conv2DTranspose stride=2\n",
        "    # BatchNorm\n",
        "    # check apply_dropout nếu True thì dùng \n",
        "    # leakyRelu \n",
        "    \n",
        "    return result\n",
        "    ###########################################"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator"
      ],
      "metadata": {
        "id": "a4aRHW-2SjJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFPI4Nu-8b4q"
      },
      "outputs": [],
      "source": [
        "\n",
        "def UNet_process(x):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    Thực hiện theo kiến trúc Unet như Generator trong hình yêu cầu \n",
        "    để loại nhiễu khỏi ảnh (Code tương tự như link hướng dẫn của tensorflow)\n",
        "    Parameters\n",
        "    ----------\n",
        "    x         : tensor \n",
        "        feature ảnh input\n",
        "    Returns\n",
        "    -------\n",
        "    x: tensor\n",
        "        ảnh xóa nhiễu\n",
        "    \"\"\"\n",
        "    # (Code tương tự như link hướng dẫn của tensorflow)\n",
        "    \n",
        "    # tạo down_stack (encoder) gồm các downsample\n",
        "    # mỗi step sẽ giảm size đi 2 lần \n",
        "    # số lượng filters mỗi step [64,256,512,512,512] qua 5 lần size sẽ giảm là 32 lần\n",
        "    # kernel_size=4\n",
        "\n",
        "    # tạo up_stack (decoder) gồm các upsample\n",
        "    # mỗi step sẽ giảm size tăng lên 2 lần và số lượng filters tăng 2\n",
        "    # số lượng filters mỗi step  [512,512,256,64] qua 5 lần size sẽ giảm là 32 lần\n",
        "    # kernel_size=4\n",
        "\n",
        "    # tạo last layer nhân 2 lần kích thước feature với Conv2DTranspose(), channel=3 cho output ảnh \n",
        "    # đã xóa nhiễu (chọn activation phù hợp)\n",
        "\n",
        "    # Downsampling through the model (Code tương tự như link hướng dẫn của tensorflow)\n",
        "    # thực vòng lập để chạy x cho mỗi layer trong down_stack\n",
        "    # đồng thời đưa kết quả mỗi layer vào list (để dùng cho skip connection)\n",
        "\n",
        "    # reverse skip connection list loại bỏ layer cuối (bridge không dùng skip connection)\n",
        "    \n",
        "    # Upsampling and establishing the skip connections (Code tương tự như link hướng dẫn của tensorflow)\n",
        "    # upsamling và concatenate với level tương ứng (element trong list skip connection)\n",
        "\n",
        "    # đi vào layer last đã tạo ở trên để ra ảnh có kích thước bằng ảnh input và đã xóa nhiễu\n",
        "    \n",
        "    return x\n",
        "    ###########################################\n",
        "        \n",
        "    \n",
        "def Generator(): \n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    Thực hiện toàn bộ task của model tạo ảnh xóa nhiễu sau đó tạo ảnh \n",
        "    supre resolution (x4 size)\n",
        "    \n",
        "    -------\n",
        "    model: tf.keras.models.Model\n",
        "        model tạo ảnh xóa nhiễu và ảnh super resolution \n",
        "    \"\"\"\n",
        "\n",
        "    # tạo layer input với shape = input low resolution image (có nhiễu)\n",
        "    \n",
        "    # extract_first_features, filters=16, kernel_size  = 3\n",
        "    \n",
        "    # Các bạn có thể lựa chọn thêm các thành phần khác để cải thiện model \n",
        "\n",
        "    # Đi vào UNet_process để denoise thu được fake_lr\n",
        "\n",
        "    # rẻ nhánh và đi tiếp vào extract_first_features filters = 64, kernel_size = 3\n",
        "    # thực hiện downsample_sr filters = 256, kernel_size = 3\n",
        "    # thực hiện downsample_sr filters = 256, kernel_size = 3\n",
        "    # thực hiện upsample_sr filters = 128, kernel_size = 4\n",
        "    # thực hiện downsample_sr filters = 128, kernel_size = 3\n",
        "    \n",
        "    # tạo layer last Conv2DTranspose filters = 6, kernel_size = 4, strides=2  (tạo ảnh high resolution) \n",
        "    # qua layer last để lấy fake_hr (chọn activation phù hợp)\n",
        "   \n",
        "    # tạo model là inputs=input layer ở trên và outputs=[fake_lr, fake_hr]\n",
        "    return model\n",
        "    ###########################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1N1_obwtdQH"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "#generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator"
      ],
      "metadata": {
        "id": "GSRVFsj6N5DI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwcatQGHN5DJ"
      },
      "outputs": [],
      "source": [
        "def Discriminator1():\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    Discrminator 1 dùng cho phân biệt ảnh low resolution \n",
        "    \n",
        "    -------\n",
        "    model: tf.keras.models.Model\n",
        "        model phân loại ảnh sau khi xóa nhiễu của model và ảnh targe_lr có giống nhau hay không \n",
        "        generator có đánh lừa được discriminator\n",
        "    \"\"\"\n",
        "    # các bạn tham khảo link sau \n",
        "    # https://www.tensorflow.org/tutorials/generative/pix2pix#build_the_discriminator\n",
        "    # phần này khá đơn giản nó hoạt động giống như 1 mạng classification bình thường đã được học \n",
        "    # các bạn có thể tùy ý thêm ý tưởng ở đây.\n",
        "    return model\n",
        "    #########################################################\n",
        "    \n",
        "def Discriminator2():\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    Discrminator 2 dùng cho phân biệt ảnh high resolution \n",
        "    \n",
        "    -------\n",
        "    model: tf.keras.models.Model\n",
        "        model phân loại ảnh sau khi model thực hiện tạo ra ảnh super resolution và ảnh targe_lr có giống nhau hay không \n",
        "        generator có đánh lừa được discriminator2\n",
        "    \"\"\"\n",
        "    # các bạn tham khảo link sau \n",
        "    # https://www.tensorflow.org/tutorials/generative/pix2pix#build_the_discriminator\n",
        "    # phần này khá đơn giản nó hoạt động giống như 1 mạng classification bình thường đã được học \n",
        "    # các bạn có thể tùy ý thêm ý tưởng ở đây.\n",
        "\n",
        "    return model\n",
        "    #########################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDkA05NE6QMs"
      },
      "outputs": [],
      "source": [
        "discriminator1 = Discriminator1()\n",
        "discriminator2 = Discriminator2()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img1 = tf.random.normal((1, IMG_HEIGHT//4, IMG_WIDTH//4, 3))\n",
        "img2 = tf.random.normal((1, IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "output1_d = discriminator1(img1)\n",
        "print(output1_d.shape)\n",
        "\n",
        "output2_d = discriminator2(img2)\n",
        "print(output2_d.shape)"
      ],
      "metadata": {
        "id": "jAVLA8YdTq-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile & Train"
      ],
      "metadata": {
        "id": "ZnI-mnvLSqRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss"
      ],
      "metadata": {
        "id": "ZdzZ-gfHS1fO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discriminator Loss"
      ],
      "metadata": {
        "id": "ab9X6Ke6WQ3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkitwiLuN5DQ"
      },
      "outputs": [],
      "source": [
        "# Khai báo BCE loss\n",
        "loss_dsic_object = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.03)\n",
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    tính loss cho Discrminator  \n",
        "    Parameters\n",
        "    ----------\n",
        "    disc_real_output         : tf.float32 (tensor)\n",
        "        Kết quả khi target đi qua discriminator \n",
        "    disc_generated_output    : tf.float32 (tensor)\n",
        "        Kết quả khi fake image  đi qua discriminator \n",
        "    -------\n",
        "    total_loss: tf.float32\n",
        "        loss tổng của discriminator\n",
        "    \"\"\"\n",
        "    # dùng loss_dsic_object tính loss disc_real_output với ma trận ones cùng size disc_real_output\n",
        "\n",
        "    # dùng loss_dsic_object tính loss disc_generated_output với ma trận zeros cùng size disc_generated_output\n",
        "\n",
        "    # total_loss = tổng 2 loss trên\n",
        "    return total_loss\n",
        "    #########################################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generator Loss"
      ],
      "metadata": {
        "id": "DevUbKi7WU4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "outputs": [],
      "source": [
        "# các bạn chọn weight cho loss\n",
        "LAMBDA = \n",
        "################################\n",
        "\n",
        "loss_gener1_object  = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "loss_gener2_object  = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "def generator_loss1(disc_generated_output, gen_output, target):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    tính loss cho generator cho phần denoise\n",
        "    Parameters\n",
        "    ----------\n",
        "    disc_generated_output         : tf.float32 (tensor)\n",
        "        Kết quả khi ảnh low resolution (xóa nhiễu) đi qua discriminator \n",
        "    gen_output    : tf.float32 (tensor)\n",
        "        Kết quả ảnh low resolution được tạo ra \n",
        "    target        : tf.float32 \n",
        "        Ảnh targe low resolution\n",
        "    -------\n",
        "    total_loss: tf.float32\n",
        "        loss tổng của generator phần denoise\n",
        "    gan_loss: tf.float32\n",
        "        loss gan phần denoise\n",
        "    l1_loss: tf.float32\n",
        "        l1 loss generator phần denoise \n",
        "    \"\"\"\n",
        "    # dùng loss_gener1_object tính gan_loss \n",
        "    # bằng cách tính loss disc_generated_output với ma trận ones cùng size disc_generated_output\n",
        "\n",
        "    # dùng L1 loss tính l1_loss giữa gen_output và target\n",
        "\n",
        "    # total_loss = tổng 2 loss trên với weight tùy theo các bạn chọn \n",
        "    return total_loss, gan_loss, l1_loss\n",
        "    #########################################################\n",
        "\n",
        "\n",
        "\n",
        "def generator_loss2(disc_generated_output, gen_output, target):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    tính loss cho generator cho phần super resolution \n",
        "    Parameters\n",
        "    ----------\n",
        "    disc_generated_output         : tf.float32 (tensor)\n",
        "        Kết quả khi ảnh high resolution được tạo từ model  đi qua discriminator \n",
        "    gen_output    : tf.float32 (tensor)\n",
        "        Kết quả ảnh high resolution được tạo ra \n",
        "    target        : tf.float32 \n",
        "        Ảnh targe high resolution\n",
        "    -------\n",
        "    total_loss: tf.float32\n",
        "        loss tổng của generator phần super resolution \n",
        "    gan_loss: tf.float32\n",
        "        loss gan phần super resolution \n",
        "    l1_loss: tf.float32\n",
        "        l1 loss generator phần super resolution \n",
        "    \"\"\"\n",
        "    # dùng loss_gener1_object tính gan_loss \n",
        "    # bằng cách tính loss disc_generated_output với ma trận ones cùng size disc_generated_output\n",
        "\n",
        "    # dùng L1 loss tính l1_loss giữa gen_output và target\n",
        "\n",
        "    # total_loss = tổng 2 loss trên với weight tùy theo các bạn chọn \n",
        "    return total_loss, gan_loss, l1_loss\n",
        "    #########################################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizers"
      ],
      "metadata": {
        "id": "Propk0jsWaUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# các bạn tùy chọn đây là mẫu\n",
        "generator_optimizer     = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "discriminator1_optimizer = tf.keras.optimizers.Adam(7e-3, beta_1=0.5)\n",
        "discriminator2_optimizer = tf.keras.optimizers.Adam(7e-3, beta_1=0.5)"
      ],
      "metadata": {
        "id": "1oTMZDsYWc99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config Checkpoint"
      ],
      "metadata": {
        "id": "bK2eAH1aWear"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJnftd5sQsv6"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = 'checkpoints'\n",
        "# chọn đường dẫn lưu checkpoints\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator1_optimizer=discriminator1_optimizer,\n",
        "                                 discriminator2_optimizer=discriminator2_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator1=discriminator1,\n",
        "                                 discriminator2=discriminator2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation and Show Result Functions"
      ],
      "metadata": {
        "id": "6GbWPvIoWnpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "outputs": [],
      "source": [
        "# phần này các bạn nên chỉnh sửa cho phù hợp với model output của mình\n",
        "def evaluate(model, image_lr, target_sr):        \n",
        "    _, fake_hr = model([image_lr], training=False)\n",
        "\n",
        "    psnr = tf.image.psnr(fake_hr, target_sr, max_val=1.0)\n",
        "    \n",
        "    psnr_mean = tf.math.reduce_mean(psnr)\n",
        "    \n",
        "    print('-------- psnr: ', psnr_mean.numpy())\n",
        "    \n",
        "    return psnr_mean\n",
        "    \n",
        "\n",
        "def generate_images(model, image_lr, target_sr):\n",
        "    _, fake_hr = model([image_lr], training=False)\n",
        "\n",
        "    display_list = [image_lr[0], target_sr[0], fake_hr[0]]\n",
        "    title_l = ['Input', 'Real', 'Generated']    \n",
        "    plt.figure(figsize=(25,25))\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title_l[i])\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Function"
      ],
      "metadata": {
        "id": "kanQ8jfLN5DT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBKUV2sKXDbY"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(image_lr, target_lr, target_hr):\n",
        "    ########### YOUR CODE HERE (OPTIONAL) ################\n",
        "    \"\"\" ĐÂY LÀ ĐOẠN CODE OPTIONAL KHÔNG BẮT BUỘC PHẢI THỰC HIỆN \n",
        "    THEO FORMAT, NẾU CÓ CÁCH KHÁC CÁC BẠN CÓ THỂ CODE THEO Ý MÌNH \n",
        "    tính loss cho generator cho phần super resolution \n",
        "    Parameters\n",
        "    ----------\n",
        "    image_lr         : tf.float32 \n",
        "        Ảnh low resolution và nhiễu\n",
        "    target_lr        : tf.float32 \n",
        "        target low resolution \n",
        "    target_hr        : tf.float32 \n",
        "        Ảnh targe high resolution\n",
        "    -------\n",
        "    gan_loss: tf.float32\n",
        "        loss tổng của generator loss\n",
        "    l1_loss: tf.float32\n",
        "        loss gan phần super resolution\n",
        "    disc_loss: tổng discriminator loss \n",
        "    \n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc1_tape, tf.GradientTape() as disc2_tape:\n",
        "        # lấy kêt quả từ generator (fake_lr, fake_hr) generator(image_lr)\n",
        "\n",
        "        # lấy disc_lr_real_output, disc_lr_generated_output từ discriminator1\n",
        "        \n",
        "        # lấy disc_hr_real_output, disc_hr_generated_output từ discriminator2\n",
        "\n",
        "        # lấy total_lr_loss, gan_lr_loss, l1_lr_loss từ generator_loss1(disc_lr_generated_output, fake_lr, target_lr)\n",
        "\n",
        "        # lấy total_hr_loss, gan_hr_loss, l1_hr_loss từ generator_loss2(disc_hr_generated_output, fake_hr, target_hr)\n",
        "\n",
        "        # lấy disc_lr_loss, discriminator_loss(disc_lr_real_output, disc_lr_generated_output)\n",
        "\n",
        "        # lấy disc_hr_loss, discriminator_loss(disc_hr_real_output, disc_hr_generated_output)\n",
        "\n",
        "        # tính gan_loss, l1_loss, disc_loss là tổng các loss liên quan \n",
        "        # vd gan_loss = gan_lr_loss + gan_hr_loss\n",
        "\n",
        "    # tính gradient cho các model tương ứng generator-gen_tape\n",
        "    # disc1_tape-discriminator1, disc2_tape-discriminator2\n",
        "\n",
        "    # apply graident cho các model tương tự như trên \n",
        "\n",
        "    return gan_loss, l1_loss, disc_loss\n",
        "    #########################################################\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "def fit(train_ds, epochs, test_ds):\n",
        "    best_psnr = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()        \n",
        "\n",
        "        # Train\n",
        "        for image_lr, target_lr, target_hr in train_ds:            \n",
        "#             \n",
        "            gan_loss, l1_loss, disc_loss = train_step(image_lr, target_lr, target_hr)\n",
        "        \n",
        "        psnr = evaluate(generator, image_lr, target_hr)        \n",
        "        if best_psnr < psnr:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "            best_psnr = psnr\n",
        "            \n",
        "            for image_lr, target_lr, target_hr in test_ds.take(1):\n",
        "                generate_images(generator, image_lr, target_hr)\n",
        "\n",
        "        \n",
        "        print('epoch {}  gan_loss: {}  l1_loss: {}  disc_loss: {}'.format(epoch, gan_loss, l1_loss, disc_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8IhZVIPN5DV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "ge5wRfxzN5DV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhBbZblwN5DW"
      },
      "outputs": [],
      "source": [
        "        \n",
        "EPOCHS = 151\n",
        "fit(train_dataset, EPOCHS, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSSm4kfvJiqv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_5flcsrN5DZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjRYyLx9N5Da"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}